{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import TFAutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amar</th>\n",
       "      <th>amar_lainnya</th>\n",
       "      <th>id</th>\n",
       "      <th>klasifikasi</th>\n",
       "      <th>lama_hukuman</th>\n",
       "      <th>lembaga_peradilan</th>\n",
       "      <th>provinsi</th>\n",
       "      <th>status</th>\n",
       "      <th>sub_klasifikasi</th>\n",
       "      <th>url</th>\n",
       "      <th>...</th>\n",
       "      <th>identitas</th>\n",
       "      <th>riwayat_penahanan</th>\n",
       "      <th>riwayat_perkara</th>\n",
       "      <th>riwayat_tuntutan</th>\n",
       "      <th>riwayat_dakwaan</th>\n",
       "      <th>fakta</th>\n",
       "      <th>amar_putusan</th>\n",
       "      <th>penutup</th>\n",
       "      <th>fakta_hukum</th>\n",
       "      <th>pertimbangan_hukum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pidana</td>\n",
       "      <td>hukum</td>\n",
       "      <td>00035681c8d944203f25d2e8215ae2bf</td>\n",
       "      <td>pidana-umum</td>\n",
       "      <td>210</td>\n",
       "      <td>pn-kudus</td>\n",
       "      <td>jateng</td>\n",
       "      <td>berkekuatan-hukum-tetap</td>\n",
       "      <td>pemalsuan</td>\n",
       "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
       "      <td>...</td>\n",
       "      <td>nama lengkap eny sulistiyaningsih binti mashad...</td>\n",
       "      <td>terdakwa ditahan dengan jenis tahanan rutan se...</td>\n",
       "      <td>pengadilan negeri tersebut\\nsetelah membaca be...</td>\n",
       "      <td>setelah mendengar tuntutan requsitoir penuntut...</td>\n",
       "      <td>menimbang bahwa terdakwa diajukan di persidang...</td>\n",
       "      <td>menimbang bahwa selanjutnya untuk membuktikan ...</td>\n",
       "      <td>mengadili 1 menyatakan terdakwa eny sulistiyan...</td>\n",
       "      <td>demikian diputuskan dalam rapat permusyawarata...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pidana</td>\n",
       "      <td>hukum</td>\n",
       "      <td>000399ce26773e18695ce14f519cb9e6</td>\n",
       "      <td>pidana-umum</td>\n",
       "      <td>720</td>\n",
       "      <td>pn-demak</td>\n",
       "      <td>jateng</td>\n",
       "      <td>berkekuatan-hukum-tetap</td>\n",
       "      <td>pencurian</td>\n",
       "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
       "      <td>...</td>\n",
       "      <td>nama lengkap ali maftuhin bin nur salim tempat...</td>\n",
       "      <td>terdakwa ditahan di rumah tahanan negara berda...</td>\n",
       "      <td>pengadilan negeri tersebut\\nsetelah membaca\\np...</td>\n",
       "      <td>setelah mendengar surat tuntutan pidana requis...</td>\n",
       "      <td>menimbang bahwa terdakwa didakwa oleh penuntut...</td>\n",
       "      <td>menimbang bahwa untuk menguatkan dakwaan terse...</td>\n",
       "      <td>mengadili 1 menyatakan terdakwa ali maftuhin b...</td>\n",
       "      <td>demikianlah diputuskan dalam rapat permusyawar...</td>\n",
       "      <td>menimbang bahwa berdasarkan keterangan saksi s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pidana</td>\n",
       "      <td>jatuh-pidana-oleh-karena-itu-kepada-dakwa-ir-b...</td>\n",
       "      <td>0006582ad67cd9bd1ddf4261a09bf382</td>\n",
       "      <td>pidana-umum</td>\n",
       "      <td>120</td>\n",
       "      <td>pn-kediri</td>\n",
       "      <td>jatim</td>\n",
       "      <td>berkekuatan-hukum-tetap</td>\n",
       "      <td>kejahatan-terhadap-keamanan-negara</td>\n",
       "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
       "      <td>...</td>\n",
       "      <td>nama lengkap ir bambang sasongko bin r soewarn...</td>\n",
       "      <td>terdakwa tidak ditahan</td>\n",
       "      <td>terdakwa didampingi oleh penasehat hukumnya ya...</td>\n",
       "      <td>telah mendengar pembacaan tuntutan pidana oleh...</td>\n",
       "      <td>menimbang bahwa terdakwa diajukan di persidang...</td>\n",
       "      <td>menimbang bahwa selanjutnya dipersidangan tela...</td>\n",
       "      <td>mengadili\\n1 menyatakan terdakwa ir bambang sa...</td>\n",
       "      <td>demikian diputuskan dalam rapat musyawarah maj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pidana</td>\n",
       "      <td>hukum</td>\n",
       "      <td>00122b1be15a10ad474bb3b7ec0dea73</td>\n",
       "      <td>pidana-umum</td>\n",
       "      <td>90</td>\n",
       "      <td>pn-sampang</td>\n",
       "      <td>jatim</td>\n",
       "      <td>berkekuatan-hukum-tetap</td>\n",
       "      <td>penghinaan</td>\n",
       "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
       "      <td>...</td>\n",
       "      <td>nama lengkap ahmad al pak saki tempat lahir sa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>terdakwa dipersidangan tidak didampingi oleh p...</td>\n",
       "      <td>telah mendengar tuntutan pidana dari penuntut ...</td>\n",
       "      <td>menimbang bahwa berdasarkan catatan penuntut u...</td>\n",
       "      <td>menimbang bahwa dalam persidangan telah dideng...</td>\n",
       "      <td>mengadili 1 menyatakan terdakwa ahmad al pak s...</td>\n",
       "      <td>demikian diputuskan pada hari senin tanggal 5 ...</td>\n",
       "      <td>menimbang bahwa berdasarkan keterangan saksi s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pidana</td>\n",
       "      <td>hukum</td>\n",
       "      <td>00136d1554e18c63256deac42aad0c58</td>\n",
       "      <td>pidana-umum</td>\n",
       "      <td>210</td>\n",
       "      <td>pn-cirebon</td>\n",
       "      <td>jabar</td>\n",
       "      <td>berkekuatan-hukum-tetap</td>\n",
       "      <td>pencurian</td>\n",
       "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
       "      <td>...</td>\n",
       "      <td>1 nama lengkap muhamad rizki als rizki bin edi...</td>\n",
       "      <td>terdakwa ditangkap pada tanggal juli 2019\\nter...</td>\n",
       "      <td>terdakwa tidak didampingi penasihat hukum\\npen...</td>\n",
       "      <td>setelah mendengar pembacaan tuntutan pidana ya...</td>\n",
       "      <td>menimbang bahwa terdakwa diajukan ke persidang...</td>\n",
       "      <td>menimbang bahwa untuk membuktikan dakwaannya p...</td>\n",
       "      <td>mengadili\\n1 menyatakan terdakwa muhamad rizki...</td>\n",
       "      <td>demikian diputuskan dalam sidang permusyawarat...</td>\n",
       "      <td>menimbang bahwa berdasarkan alat bukti dan bar...</td>\n",
       "      <td>menimbang bahwa selanjutnya majelis hakim akan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     amar                                       amar_lainnya  \\\n",
       "0  pidana                                              hukum   \n",
       "1  pidana                                              hukum   \n",
       "2  pidana  jatuh-pidana-oleh-karena-itu-kepada-dakwa-ir-b...   \n",
       "3  pidana                                              hukum   \n",
       "4  pidana                                              hukum   \n",
       "\n",
       "                                 id  klasifikasi  lama_hukuman  \\\n",
       "0  00035681c8d944203f25d2e8215ae2bf  pidana-umum           210   \n",
       "1  000399ce26773e18695ce14f519cb9e6  pidana-umum           720   \n",
       "2  0006582ad67cd9bd1ddf4261a09bf382  pidana-umum           120   \n",
       "3  00122b1be15a10ad474bb3b7ec0dea73  pidana-umum            90   \n",
       "4  00136d1554e18c63256deac42aad0c58  pidana-umum           210   \n",
       "\n",
       "  lembaga_peradilan provinsi                   status  \\\n",
       "0          pn-kudus   jateng  berkekuatan-hukum-tetap   \n",
       "1          pn-demak   jateng  berkekuatan-hukum-tetap   \n",
       "2         pn-kediri    jatim  berkekuatan-hukum-tetap   \n",
       "3        pn-sampang    jatim  berkekuatan-hukum-tetap   \n",
       "4        pn-cirebon    jabar  berkekuatan-hukum-tetap   \n",
       "\n",
       "                      sub_klasifikasi  \\\n",
       "0                           pemalsuan   \n",
       "1                           pencurian   \n",
       "2  kejahatan-terhadap-keamanan-negara   \n",
       "3                          penghinaan   \n",
       "4                           pencurian   \n",
       "\n",
       "                                                 url  ...  \\\n",
       "0  https://putusan3.mahkamahagung.go.id/direktori...  ...   \n",
       "1  https://putusan3.mahkamahagung.go.id/direktori...  ...   \n",
       "2  https://putusan3.mahkamahagung.go.id/direktori...  ...   \n",
       "3  https://putusan3.mahkamahagung.go.id/direktori...  ...   \n",
       "4  https://putusan3.mahkamahagung.go.id/direktori...  ...   \n",
       "\n",
       "                                           identitas  \\\n",
       "0  nama lengkap eny sulistiyaningsih binti mashad...   \n",
       "1  nama lengkap ali maftuhin bin nur salim tempat...   \n",
       "2  nama lengkap ir bambang sasongko bin r soewarn...   \n",
       "3  nama lengkap ahmad al pak saki tempat lahir sa...   \n",
       "4  1 nama lengkap muhamad rizki als rizki bin edi...   \n",
       "\n",
       "                                   riwayat_penahanan  \\\n",
       "0  terdakwa ditahan dengan jenis tahanan rutan se...   \n",
       "1  terdakwa ditahan di rumah tahanan negara berda...   \n",
       "2                             terdakwa tidak ditahan   \n",
       "3                                                NaN   \n",
       "4  terdakwa ditangkap pada tanggal juli 2019\\nter...   \n",
       "\n",
       "                                     riwayat_perkara  \\\n",
       "0  pengadilan negeri tersebut\\nsetelah membaca be...   \n",
       "1  pengadilan negeri tersebut\\nsetelah membaca\\np...   \n",
       "2  terdakwa didampingi oleh penasehat hukumnya ya...   \n",
       "3  terdakwa dipersidangan tidak didampingi oleh p...   \n",
       "4  terdakwa tidak didampingi penasihat hukum\\npen...   \n",
       "\n",
       "                                    riwayat_tuntutan  \\\n",
       "0  setelah mendengar tuntutan requsitoir penuntut...   \n",
       "1  setelah mendengar surat tuntutan pidana requis...   \n",
       "2  telah mendengar pembacaan tuntutan pidana oleh...   \n",
       "3  telah mendengar tuntutan pidana dari penuntut ...   \n",
       "4  setelah mendengar pembacaan tuntutan pidana ya...   \n",
       "\n",
       "                                     riwayat_dakwaan  \\\n",
       "0  menimbang bahwa terdakwa diajukan di persidang...   \n",
       "1  menimbang bahwa terdakwa didakwa oleh penuntut...   \n",
       "2  menimbang bahwa terdakwa diajukan di persidang...   \n",
       "3  menimbang bahwa berdasarkan catatan penuntut u...   \n",
       "4  menimbang bahwa terdakwa diajukan ke persidang...   \n",
       "\n",
       "                                               fakta  \\\n",
       "0  menimbang bahwa selanjutnya untuk membuktikan ...   \n",
       "1  menimbang bahwa untuk menguatkan dakwaan terse...   \n",
       "2  menimbang bahwa selanjutnya dipersidangan tela...   \n",
       "3  menimbang bahwa dalam persidangan telah dideng...   \n",
       "4  menimbang bahwa untuk membuktikan dakwaannya p...   \n",
       "\n",
       "                                        amar_putusan  \\\n",
       "0  mengadili 1 menyatakan terdakwa eny sulistiyan...   \n",
       "1  mengadili 1 menyatakan terdakwa ali maftuhin b...   \n",
       "2  mengadili\\n1 menyatakan terdakwa ir bambang sa...   \n",
       "3  mengadili 1 menyatakan terdakwa ahmad al pak s...   \n",
       "4  mengadili\\n1 menyatakan terdakwa muhamad rizki...   \n",
       "\n",
       "                                             penutup  \\\n",
       "0  demikian diputuskan dalam rapat permusyawarata...   \n",
       "1  demikianlah diputuskan dalam rapat permusyawar...   \n",
       "2  demikian diputuskan dalam rapat musyawarah maj...   \n",
       "3  demikian diputuskan pada hari senin tanggal 5 ...   \n",
       "4  demikian diputuskan dalam sidang permusyawarat...   \n",
       "\n",
       "                                         fakta_hukum  \\\n",
       "0                                                NaN   \n",
       "1  menimbang bahwa berdasarkan keterangan saksi s...   \n",
       "2                                                NaN   \n",
       "3  menimbang bahwa berdasarkan keterangan saksi s...   \n",
       "4  menimbang bahwa berdasarkan alat bukti dan bar...   \n",
       "\n",
       "                                  pertimbangan_hukum  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  menimbang bahwa selanjutnya majelis hakim akan...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/dataset_csv/dataset_pidana_umum.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pilih fitur dan label\n",
    "features = df['riwayat_dakwaan']  # Teks yang digunakan untuk prediksi\n",
    "labels = df['sub_klasifikasi']    # Kategori pidana\n",
    "\n",
    "# Drop nilai kosong dan pastikan input valid\n",
    "df = df.dropna(subset=['riwayat_dakwaan', 'sub_klasifikasi'])\n",
    "df['riwayat_dakwaan'] = df['riwayat_dakwaan'].astype(str)\n",
    "\n",
    "# Encode Label\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Split data menjadi train dan test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load IndoBERT dan Tokenizer\n",
    "model_name = \"indobenchmark/indobert-base-p2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenisasi teks\n",
    "def tokenize_texts(texts, tokenizer, max_length=200):\n",
    "    # Validasi input: konversi ke string dan filter nilai kosong\n",
    "    texts = [str(text) for text in texts if isinstance(text, str) and text.strip() != \"\"]\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "X_train = X_train.astype(str)\n",
    "X_test = X_test.astype(str)\n",
    "\n",
    "train_encodings = tokenize_texts(X_train, tokenizer)\n",
    "test_encodings = tokenize_texts(X_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\.virtualenvs\\Machine_Learning-95sCrP9Y\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.virtualenvs\\Machine_Learning-95sCrP9Y\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ASUS\\.cache\\huggingface\\hub\\models--indobenchmark--indobert-base-p2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\.virtualenvs\\Machine_Learning-95sCrP9Y\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 146. MiB for an array with shape (50000, 768) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m200\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m200\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m pretrained_bert \u001b[38;5;241m=\u001b[39m \u001b[43mTFAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m bert_outputs \u001b[38;5;241m=\u001b[39m pretrained_bert(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[0;32m      7\u001b[0m cls_token \u001b[38;5;241m=\u001b[39m bert_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# Ambil representasi token [CLS]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\Machine_Learning-95sCrP9Y\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\Machine_Learning-95sCrP9Y\\lib\\site-packages\\transformers\\modeling_tf_utils.py:3032\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3024\u001b[0m             missing_keys, unexpected_keys, mismatched_keys \u001b[38;5;241m=\u001b[39m load_tf_sharded_weights(\n\u001b[0;32m   3025\u001b[0m                 model,\n\u001b[0;32m   3026\u001b[0m                 resolved_archive_file,\n\u001b[0;32m   3027\u001b[0m                 ignore_mismatched_sizes\u001b[38;5;241m=\u001b[39mignore_mismatched_sizes,\n\u001b[0;32m   3028\u001b[0m                 _prefix\u001b[38;5;241m=\u001b[39mload_weight_prefix,\n\u001b[0;32m   3029\u001b[0m             )\n\u001b[0;32m   3030\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3031\u001b[0m         \u001b[38;5;66;03m# Handles both H5 and safetensors\u001b[39;00m\n\u001b[1;32m-> 3032\u001b[0m         missing_keys, unexpected_keys, mismatched_keys \u001b[38;5;241m=\u001b[39m \u001b[43mload_tf_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3033\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3034\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3035\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3036\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_weight_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3037\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3038\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3039\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\Machine_Learning-95sCrP9Y\\lib\\site-packages\\transformers\\modeling_tf_utils.py:952\u001b[0m, in \u001b[0;36mload_tf_weights\u001b[1;34m(model, resolved_archive_file, ignore_mismatched_sizes, _prefix)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    950\u001b[0m     load_function \u001b[38;5;241m=\u001b[39m load_tf_weights_from_h5\n\u001b[1;32m--> 952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prefix\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\Machine_Learning-95sCrP9Y\\lib\\site-packages\\transformers\\modeling_tf_utils.py:994\u001b[0m, in \u001b[0;36mload_tf_weights_from_h5\u001b[1;34m(model, resolved_archive_file, ignore_mismatched_sizes, _prefix)\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    992\u001b[0m     name \u001b[38;5;241m=\u001b[39m _prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name\n\u001b[1;32m--> 994\u001b[0m saved_weights[name] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh5_layer_object\u001b[49m\u001b[43m[\u001b[49m\u001b[43mweight_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;66;03m# Add the updated name to the final list for computing missing/unexpected values\u001b[39;00m\n\u001b[0;32m    997\u001b[0m saved_weight_names_set\u001b[38;5;241m.\u001b[39madd(name)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\Machine_Learning-95sCrP9Y\\lib\\site-packages\\h5py\\_hl\\dataset.py:1085\u001b[0m, in \u001b[0;36mDataset.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset.__array__ received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcopy\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1083\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut memory allocation cannot be avoided on read\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1084\u001b[0m     )\n\u001b[1;32m-> 1085\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;66;03m# Special case for (0,)*-shape datasets\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 146. MiB for an array with shape (50000, 768) and data type float32"
     ]
    }
   ],
   "source": [
    "# 3. Functional API untuk Model\n",
    "input_ids = tf.keras.layers.Input(shape=(200,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = tf.keras.layers.Input(shape=(200,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "pretrained_bert = TFAutoModel.from_pretrained(model_name)\n",
    "bert_outputs = pretrained_bert(input_ids, attention_mask=attention_mask)\n",
    "cls_token = bert_outputs.last_hidden_state[:, 0, :]  # Ambil representasi token [CLS]\n",
    "\n",
    "dense_layer = tf.keras.layers.Dense(128, activation='relu')(cls_token)\n",
    "dropout_layer = tf.keras.layers.Dropout(0.3)(dense_layer)\n",
    "output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')(dropout_layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "history = model.fit(\n",
    "    x={\n",
    "        \"input_ids\": train_encodings['input_ids'],\n",
    "        \"attention_mask\": train_encodings['attention_mask']\n",
    "    },\n",
    "    y=y_train,\n",
    "    validation_data=(\n",
    "        {\n",
    "            \"input_ids\": test_encodings['input_ids'],\n",
    "            \"attention_mask\": test_encodings['attention_mask']\n",
    "        },\n",
    "        y_test\n",
    "    ),\n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi Model\n",
    "loss, accuracy = model.evaluate(\n",
    "    x={\n",
    "        \"input_ids\": test_encodings['input_ids'],\n",
    "        \"attention_mask\": test_encodings['attention_mask']\n",
    "    },\n",
    "    y=y_test\n",
    ")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi pada Data Baru\n",
    "predictions = model.predict({\n",
    "    \"input_ids\": test_encodings['input_ids'][:5],\n",
    "    \"attention_mask\": test_encodings['attention_mask'][:5]\n",
    "})\n",
    "predicted_classes = label_encoder.inverse_transform(predictions.argmax(axis=1))\n",
    "print(\"Predicted Categories:\", predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Menimbang, bahwa terdakwa...\"\n",
    "tokenized_example = tokenizer(example_text, max_length=200, padding=\"max_length\", truncation=True)\n",
    "print(tokenized_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine_Learning-95sCrP9Y",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
